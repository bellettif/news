{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import socks\n",
    "import socket\n",
    "import urllib\n",
    "import urllib2\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import stopit\n",
    "import zlib\n",
    "\n",
    "TIMEOUT = 1.0 # 1 second\n",
    "N_PROC = 16\n",
    "MAX_LINE_LENGTH = 4000\n",
    "\n",
    "targets = map(lambda x : x.lower(),\n",
    "              [\"Trump\", \n",
    "               \"Cruz\", \n",
    "               \"Rubio\", \n",
    "               \"Carson\",\n",
    "               \"Paul\",\n",
    "               \"Bush\",\n",
    "               \"Huckabee\",\n",
    "               \"Kasich\",\n",
    "               \"Fiorina\",\n",
    "               \"Christie\",\n",
    "               \"Santorum\",\n",
    "               \"O'Malley\",\n",
    "               \"Clinton\", \n",
    "               \"Sanders\", \n",
    "               \"ad\", \n",
    "               \"commercial\"])\n",
    "\n",
    "event_table_headers = ['GLOBALEVENTID',\n",
    "                       'SQLDATE',\n",
    "                       'MonthYear',\n",
    "                       'Year',\n",
    "                       'FractionDate',\n",
    "                       'Actor1Code',\n",
    "                       'Actor1Name',\n",
    "                       'Actor1CountryCode',\n",
    "                       'Actor1KnownGroupCode',\n",
    "                       'Actor1EthnicCode',\n",
    "                       'Actor1Religion1Code',\n",
    "                       'Actor1Religion2Code',\n",
    "                       'Actor1Type1Code',\n",
    "                       'Actor1Type2Code',\n",
    "                       'Actor1Type3Code',\n",
    "                       'Actor2Code',\n",
    "                       'Actor2Name',\n",
    "                       'Actor2CountryCode',\n",
    "                       'Actor2KnownGroupCode',\n",
    "                       'Actor2EthnicCode',\n",
    "                       'Actor2Religion1Code',\n",
    "                       'Actor2Religion2Code',\n",
    "                       'Actor2Type1Code',\n",
    "                       'Actor2Type2Code',\n",
    "                       'Actor2Type3Code',\n",
    "                       'IsRootEvent',\n",
    "                       'EventCode',\n",
    "                       'EventBaseCode',\n",
    "                       'EventRootCode',\n",
    "                       'QuadClass',\n",
    "                       'GoldsteinScale',\n",
    "                       'NumMentions', \n",
    "                       'NumSources',\n",
    "                       'NumArticles',\n",
    "                       'AvgTone',\n",
    "                       'Actor1Geo_Type',\n",
    "                       'Actor1Geo_FullName',\n",
    "                       'Actor1Geo_CountryCode',\n",
    "                       'Actor1Geo_ADM1Code',\n",
    "                       'Actor1Geo_Lat',\n",
    "                       'Actor1Geo_Long',\n",
    "                       'Actor1Geo_FeatureID',\n",
    "                       'Actor2Geo_Type',\n",
    "                       'Actor2Geo_FullName',\n",
    "                       'Actor2Geo_CountryCode',\n",
    "                       'Actor2Geo_ADM1Code',\n",
    "                       'Actor2Geo_Lat',\n",
    "                       'Actor2Geo_Long',\n",
    "                       'Actor2Geo_FeatureID',\n",
    "                       'ActionGeo_Type',\n",
    "                       'ActionGeo_FullName',\n",
    "                       'ActionGeo_CountryCode',\n",
    "                       'ActionGeo_ADM1Code',\n",
    "                       'ActionGeo_Lat',\n",
    "                       'ActionGeo_Long',\n",
    "                       'ActionGeo_FeatureID',\n",
    "                       'DATEADDED',\n",
    "                       'SOURCEURL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_freqs(targets, url):\n",
    "\n",
    "    \"\"\"\n",
    "    def create_connection(address, timeout=None, source_address=None):\n",
    "        sock = socks.socksocket()\n",
    "        sock.connect(address)\n",
    "        return sock\n",
    "\n",
    "    socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS5, \"127.0.0.1\", 9050)\n",
    "\n",
    "    # patch the socket module\n",
    "    socket.socket = socks.socksocket\n",
    "    socket.create_connection = create_connection\n",
    "    # ...\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.clock()\n",
    "    try:\n",
    "        \n",
    "        with stopit.ThreadingTimeout(3) as to_ctx_mgr:\n",
    "            assert to_ctx_mgr.state == to_ctx_mgr.EXECUTING\n",
    "            \n",
    "            try:\n",
    "        \n",
    "                user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'\n",
    "                values = {'name' : 'Micael Foord',\n",
    "                          'location' : 'Northmpton',\n",
    "                          'language' : 'Python' }\n",
    "                headers = { 'User-Agent' : user_agent, 'Content-Type' : 'html/text' }\n",
    "\n",
    "                data = urllib.urlencode(values)\n",
    "                req = urllib2.Request(url, data, headers)\n",
    "                html = urllib2.urlopen(req, timeout = TIMEOUT).read()\n",
    "                soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "                # kill all script and style elements\n",
    "                for script in soup([\"script\", \"style\"]):\n",
    "                    script.extract()    # rip it out\n",
    "\n",
    "                # get text\n",
    "                text = soup.get_text()\n",
    "\n",
    "                # break into lines and remove leading and trailing space on each\n",
    "                lines = (line.strip() for line in text.splitlines() )\n",
    "                # break multi-headlines into a line each\n",
    "                chunks = [zlib.compress(line.strip().encode('utf-8'))                        \n",
    "                          for line in lines\n",
    "                          if len(line) < MAX_LINE_LENGTH]\n",
    "                # drop blank lines                                \n",
    "\n",
    "                return chunks, time.clock() - start_time, None\n",
    "            \n",
    "            except Exception as e:\n",
    "                return None, time.clock() - start_time, repr(e)\n",
    "                \n",
    "        return None, time.clock() - start_time, 'Exceeded timeout for processing'\n",
    "\n",
    "    except (Exception, KeyboardInterrupt, SystemExit) as e:\n",
    "        return None, time.clock() - start_time, repr(e)\n",
    "\n",
    "def extract_freqs_(args):\n",
    "    return extract_freqs(args[0], args[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INPUT_FOLDER = '../GDELT/'\n",
    "OUTPUT_FOLDER = '../GDELT_grepped/'\n",
    "\n",
    "stride = 2 * N_PROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (8,9,10,11,12,13,14,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n"
     ]
    }
   ],
   "source": [
    "file_name = np.random.permutation(os.listdir(INPUT_FOLDER))[0]\n",
    "\n",
    "event_table = pd.read_csv(INPUT_FOLDER + file_name, \n",
    "                          sep = '\\t', \n",
    "                          header = None, \n",
    "                          names = event_table_headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123501\n",
      "26454\n"
     ]
    }
   ],
   "source": [
    "count_table = event_table.copy()\n",
    "count_table['grabed'] = None\n",
    "\n",
    "p = Pool(N_PROC)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "letter_counts = Counter(event_table['SOURCEURL'].apply(lambda x : x.split('/')[:3][-1]))\n",
    "\n",
    "targets = [y[0] for y in sorted(letter_counts.items(), key = (lambda x : - x[1]))[:50]]\n",
    "\n",
    "print len(event_table)\n",
    "event_table = event_table[event_table.apply(lambda x : x['SOURCEURL'].split('/')[:3][-1], axis = 1).isin(targets)]\n",
    "print len(event_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20130802.export.CSV chunk 0 out of 827\n",
      "32\n",
      "0.182215\n",
      "Processing 20130802.export.CSV chunk 1 out of 827\n",
      "32\n",
      "0.041342\n",
      "Processing 20130802.export.CSV chunk 2 out of 827\n",
      "32\n",
      "0.033011\n",
      "Processing 20130802.export.CSV chunk 3 out of 827\n",
      "32\n",
      "0.033107\n",
      "Processing 20130802.export.CSV chunk 4 out of 827\n",
      "32\n",
      "0.032188\n",
      "Processing 20130802.export.CSV chunk 5 out of 827\n",
      "32\n",
      "0.03223\n",
      "Processing 20130802.export.CSV chunk 6 out of 827\n",
      "32\n",
      "0.034006\n",
      "Processing 20130802.export.CSV chunk 7 out of 827\n",
      "32\n",
      "0.035999\n",
      "Processing 20130802.export.CSV chunk 8 out of 827\n",
      "32\n",
      "0.033318\n",
      "Processing 20130802.export.CSV chunk 9 out of 827\n",
      "32\n",
      "0.031963\n",
      "Processing 20130802.export.CSV chunk 10 out of 827\n",
      "32\n",
      "0.03259\n",
      "Processing 20130802.export.CSV chunk 11 out of 827\n",
      "32\n",
      "0.032704\n",
      "Processing 20130802.export.CSV chunk 12 out of 827\n",
      "32\n",
      "0.032402\n",
      "Processing 20130802.export.CSV chunk 13 out of 827\n",
      "32\n",
      "0.042584\n",
      "Processing 20130802.export.CSV chunk 14 out of 827\n",
      "32\n",
      "0.031933\n",
      "Processing 20130802.export.CSV chunk 15 out of 827\n",
      "32\n",
      "0.03274\n",
      "Processing 20130802.export.CSV chunk 16 out of 827\n",
      "32\n",
      "0.033576\n",
      "Processing 20130802.export.CSV chunk 17 out of 827\n",
      "32\n",
      "0.036103\n",
      "Processing 20130802.export.CSV chunk 18 out of 827\n",
      "32\n",
      "0.037012\n",
      "Processing 20130802.export.CSV chunk 19 out of 827\n",
      "32\n",
      "0.033686\n",
      "Processing 20130802.export.CSV chunk 20 out of 827\n",
      "32\n",
      "0.033008\n",
      "Processing 20130802.export.CSV chunk 21 out of 827\n",
      "32\n",
      "0.034871\n",
      "Processing 20130802.export.CSV chunk 22 out of 827\n",
      "32\n",
      "0.035355\n",
      "Processing 20130802.export.CSV chunk 23 out of 827\n",
      "32\n",
      "0.037614\n",
      "Processing 20130802.export.CSV chunk 24 out of 827\n",
      "32\n",
      "0.051295\n",
      "Processing 20130802.export.CSV chunk 25 out of 827\n",
      "32\n",
      "0.048409\n",
      "Processing 20130802.export.CSV chunk 26 out of 827\n",
      "32\n",
      "0.034053\n",
      "Processing 20130802.export.CSV chunk 27 out of 827\n",
      "32\n",
      "0.035229\n",
      "Processing 20130802.export.CSV chunk 28 out of 827\n",
      "32\n",
      "0.035611"
     ]
    }
   ],
   "source": [
    "n_events = len(event_table)\n",
    "for i in xrange((n_events / stride) + 1):\n",
    "#for i in xrange(3):\n",
    "    start_chunk = time.clock()\n",
    "    print 'Processing ' + str(file_name) + ' chunk ' + str(i) + ' out of ' + str(n_events / stride + 1) \n",
    "    start = i * stride\n",
    "    end = min((i + 1) * stride, n_events)\n",
    "    chunk = event_table[start : end]\n",
    "    print len(chunk)\n",
    "    count_table['grabed'][start:end] = p.map(extract_freqs_, zip([targets] * len(chunk), chunk['SOURCEURL'].values))\n",
    "    #count_table.to_csv(OUTPUT_FOLDER + 'counts_' + file_name)\n",
    "    print time.clock() - start_chunk\n",
    "print 'Done processing ' + str(file_name)\n",
    "count_table.to_csv(OUTPUT_FOLDER + 'counts_' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print count_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
